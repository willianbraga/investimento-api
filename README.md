üìå Investimento API

Este projeto √© parte de um desafio t√©cnico onde estou desenvolvendo uma API para consulta e cadastro de investimentos de clientes. Durante a implementa√ß√£o, estou ajustando o cronograma e as decis√µes t√©cnicas conforme necess√°rio, sempre buscando uma solu√ß√£o simples, funcional e bem estruturada. No final do documento tem um passo a passo de como rodar a aplica√ß√£o.


üìÖ Cronograma do Projeto
| Dia  | Tarefa | Tempo Estimado | Realizado |
| ------------- | ------------- | ------------ | ------------ |
| 1Ô∏è‚É£  | Configura√ß√£o inicial  | 5h | 3h |
| 2Ô∏è‚É£  | Implementa√ß√£o do endpoint  | 5h | 3,5h |
| 3Ô∏è‚É£  | Testes  | 5h | 4h |
| 4Ô∏è‚É£  | Observabilidade  | 8h | 7h |
| 5Ô∏è‚É£  | Docker  | 5h | 8h |
| 6Ô∏è‚É£  | AWS e ajustes gerais  | 5h | 3h |
| 7Ô∏è‚É£  | Documenta√ß√£o e revis√£o final  | 5h | 3h |


üìå Como Dividi as Tarefas
| Dia  | Tarefa | Tempo Estimado | Realizado |
| ------------- | ------------- | ------------ | ------------ |
| 1Ô∏è‚É£   | Criar reposit√≥rio e estrutura  | 1,5h | 1h |
|      | Configurar banco de dados  | 2h | 1h |
|     | Criar endpoint mock  | 2h | 0,5h |
|     | Versionamento inicial  | 0,5h | 0,5h |
| 2Ô∏è‚É£  | Criar reposit√≥rio  | 2h | 1h |
|   | Implementar endpoint real  | 2h | 2h |
|   | Testar API local  | 1h | 0,5h |
| 3Ô∏è‚É£  | Criar testes unit√°rios  | 1,5h | 1h |
|   | Criar testes de integra√ß√£o  | 1,5h | 1h |
|   | Executar e corrigir falhas  | 2h | 2h |
| 4Ô∏è‚É£  | Estudar Serilog, OpenTelemetry e Prometheus  | 2,5h | 1h |
|   | Implementar Serilog  | 1,5h | 1h |
|   | Implementar Seq | 1,5h | 1h |
|   | Implementar OpenTelemetry  | 1,5h | 1h |
|   | Implementar Prometheus  | 1,5h | 1h |
|   | Implementar Grafana | 1,5h | 1h |
|   | Executar e corrigir falhas  | 1h | 2h |
| 5Ô∏è‚É£  | Estudar Docker  | 1h | 2h |
|   | Criar Dockerfile  | 2h | 1h |
|   | Criar docker-compose  | 2h | 1h |
|   | Migrar solu√ß√£o para Docker | 2h | 4h |
| 6Ô∏è‚É£  | Estudo AWS  | 2h | 1,5h |
|   | Criar desenho de arquitetura  | 2h | 1h |
|   | Ajustes finais  | 1h | 0,5h |
| 7Ô∏è‚É£  | Escrever documenta√ß√£o  | 3h |
|   | Revis√£o final  | 2,5h |  0,5h |
|   | Ajustes extra  | 2,5h | 2h |
|   | Commit final  | 0,5h | 0,5h |



üöÄ Andamento do Projeto

‚úÖ Dia 1 - Configura√ß√£o Inicial (Tempo gasto: **3h**)

O primeiro dia foi mais focado no planejamento e na cria√ß√£o da estrutura base do projeto. 
Quis definir um modelo que fosse organizado e flex√≠vel, ent√£o escolhi seguir DDD (Domain-Driven Design) e pensei em uma estrutura SOA (Service-Oriented Architecture).

Nesse momento, n√£o quis complicar demais com microsservi√ßos, ent√£o mantive tudo dentro de uma API monol√≠tica, mas com organiza√ß√£o modular para facilitar qualquer refatora√ß√£o futura.

üîπ O que foi feito?

- [x] Estruturado o projeto no GitHub
- [x] Criado reposit√≥rio e organizado as camadas (Controller ‚Üí AppService ‚Üí Service ‚Üí Repository)
- [x] Configurado o banco de dados SQL Server
- [x] Criado um endpoint mockado para testes iniciais


‚úÖ Dia 2 - Implementa√ß√£o dos Endpoints e Banco de Dados (Tempo gasto: **3,5h**)


No segundo dia, veio a d√∫vida sobre usar RabbitMQ e quebrar a API em uma arquitetura separada entre API e Worker. Eu pensei bastante sobre isso e vi que poderia ser uma boa ideia, mas, por enquanto, decidi seguir com a API monol√≠tica para garantir que a entrega fosse funcional. Se sobrar tempo, fa√ßo uma an√°lise mais detalhada sobre a viabilidade dessa mudan√ßa.

üîπ O que foi feito?

- [x] Finalizado reposit√≥rio, contexto do banco e inje√ß√£o de depend√™ncias
- [x] Implementa√ß√£o da l√≥gica real para os endpoints
- [x] Testes manuais via Postman para garantir que a API responde corretamente

üîπ Decis√£o t√©cnica importante:
- [x] RabbitMQ fica em pausa ‚Äì Decidi manter o foco na API monol√≠tica e avaliar a necessidade da fila depois.

‚úÖ Dia 3 ‚Üí Testes unit√°rios e de integra√ß√£o (Tempo gasto: **4h**)

Iniciando o terceiro dia com foco na implementa√ß√£o dos testes unit√°rios e de integra√ß√£o. Se poss√≠vel, tentarei adiantar parte do desenvolvimento do Dia 4 para ganhar tempo extra para poss√≠veis melhorias no projeto.

üîπ O que foi feito?

- [x] Testes unit√°rios no reposit√≥rio e servi√ßos
- [x] Testes de integra√ß√£o corrigidos e rodando sem erros
- [x] Refatora√ß√µes para melhorar performance e depura√ß√£o

üîπ Decis√£o
- [x] Irei puxar alguma parte do dia 4 para adiantar parte do desenvolvimento e ganhar tempo.
  
üîπ Decis√£o t√©cnica importante:

Durante o estudo sobre logs estruturados, avaliei algumas op√ß√µes para melhorar a visualiza√ß√£o e an√°lise dos logs da API. Inicialmente, a ideia era apenas utilizar Serilog gravando em arquivo, mas percebi que isso poderia dificultar a leitura e a busca por eventos espec√≠ficos.

Ap√≥s estudar algumas solu√ß√µes, decidi integrar o Seq, que oferece uma interface web intuitiva para an√°lise dos logs em tempo real. Com essa mudan√ßa, agora posso monitorar os eventos da API de forma mais organizada, com filtros e buscas estruturadas.

üîπ Decis√£o tomada:

- [x] Implementar Serilog com Seq para melhorar a rastreabilidade dos logs.
- [x] Configurar o Seq localmente, permitindo an√°lise em tempo real.
- [x] Manter a possibilidade de adicionar novos sinks (exemplo: arquivos, cloud, banco de dados) no futuro, se necess√°rio.

Fiquei pensando... Com Serilog, OpenTelemetry e Prometheus/Grafana no projeto, ser√° que realmente precisamos do Seq? No fim das contas as informa√ß√µes poderiam ser enviadas diretamente entre essas ferramentas ou at√© armazenadas em arquivos, banco ou outro destino sem depender dele. Hummm, por enquanto acho que vale a pena manter. Ele facilita a organiza√ß√£o dos logs e torna o rastreamento de eventos bem mais pr√°tico. Se em algum momento come√ßar a virar um peso extra de administra√ß√£o ou deixar de fazer sentido, d√° pra remover sem grandes impactos. A estrutura j√° est√° flex√≠vel o suficiente pra isso.

üîπ O que foi feito? (**3h**)

- [x] Implementa√ß√£o do OpenTelemetry
- [x] Habilita√ß√£o do suporte OTLP no Seq
- [x] Estudo sobre a necessidade do Seq

‚úÖ Dia 4 ‚Üí Observabilidade com Serilog, OpenTelemetry e Prometheus/Grafana (Tempo gasto: **7h**)

Como no dia anterior adiantei parte do Serilog, OpenTelemetry e da integra√ß√£o com o Seq, darei foco na finaliza√ß√£o do Prometheus e Grafana.

üîπ O que foi feito? (**4h**)

- [x] Instalei e configurei o Prometheus e Grafana localmente
- [x] Implementei a captura de m√©tricas na API usando o prometheus-net
- [x] Ajustei o Prometheus para coletar as m√©tricas corretamente
- [x] Efetuei v√°rios requests para garantir que os dados estavam sendo armazenados
- [x] Testei as consultas no Prometheus e configurei dashboards no Grafana
- [x] Fiz ajustes finais e tudo est√° funcional

Agora tentar adiantar a parte do Docker para otimizar o tempo e preparar a API para rodar de forma isolada.

üîπ O que foi feito? (**2h**)

- [x] Adiantado a instala√ß√£o das ferramentas necessarias.
- [x] Efetuado a organiza√ß√£o estrutural dos arquivos na solu√ß√£o
- [x] Iniciado a cria√ß√£o do DOCKERFILE e docker-compose.yaml

‚úÖ Dia 5 ‚Üí Preparar a API para rodar no Docker (Tempo gasto: **8h**)

Ontem j√° tinha adiantado boa parte dos arquivos de configura√ß√£o, ent√£o hoje a ideia √© focar nos testes e ajustes da aplica√ß√£o rodando no Docker.

üîπ O que aconteceu?

Tive alguns problemas de recurso computacional, o Docker ficou inst√°vel e come√ßou a crashar v√°rias vezes. No come√ßo tentei automatizar tudo ao m√°ximo criando um entrypoint que configurava o banco, rodava um script para criar o banco, usu√°rio, permiss√µes e tudo mais. Fiz o script e tudo parecia bem mas come√ßaram a surgir v√°rios desafios na automatiza√ß√£o total do banco e do migration.

No fim das contas percebi que isso estava tomando muito tempo. Ent√£o decidi simplificar. 
Vou deixar o Docker cuidando da API, do banco, do Seq, do Prometheus e do Grafana, mas a inicializa√ß√£o do banco vai ser manual (rodando o entrypoint e a migration na m√£o). Se no futuro isso virar um problema, a√≠ penso em uma solu√ß√£o mais automatizada.

üîπ O que foi feito? (**6h**)

- [x] Finalizada a configura√ß√£o do Dockerfile e docker-compose.yaml
- [x] Criei o entrypoint.sh e o init-db.sql para inicializar o banco
- [x] Resolvi o problema de restart infinito do container do SQL Server
- [x] Ajustei a conex√£o entre a API e o banco dentro do Docker
- [x] Testei a API e o banco rodando nos containers
- [x] Validei que a API funciona tanto localmente quanto via Docker
- [x] Ajustei o appsettings.json para suportar os dois ambientes (Docker/local)
- [x] Testei e finalizei a migra√ß√£o do banco no ambiente Docker

Como estava no pique, resolvi adiantar o Dia 6 e focar no desenho da arquitetura da solu√ß√£o na AWS.

‚úÖ Dia 6 ‚Üí Estudo AWS, Desenho da solu√ß√£o utilizando servi√ßos AWS (Tempo gasto: **3h**)

Passei um tempo estudando os servi√ßos da AWS para entender como encaixar tudo na arquitetura da minha API. Como n√£o tenho tanta experi√™ncia com AWS, minha ideia foi evitar complica√ß√µes desnecess√°rias e escolher servi√ßos que a pr√≥pria AWS j√° gerencia para mim.

üîπ Decis√µes que tomei

üìå API e Balanceamento de Carga
A API vai rodar no AWS Fargate com Auto Scaling, ent√£o n√£o preciso me preocupar em subir e gerenciar servidores. A AWS cuida disso, e a API escala automaticamente conforme a demanda. Para garantir que o tr√°fego seja distribu√≠do corretamente, adicionei um Elastic Load Balancer, que ajuda na disponibilidade.

üìå Banco de Dados
Como preciso usar SQL Server eu optei pelo Amazon RDS que j√° gerencia backups, replica√ß√£o e escalabilidade de forma autom√°tica. Tem suporte para rodar em Multi-AZ garantindo disponibilidade caso uma zona caia.

üìå Observabilidade e Logs
Sobre Observabilidade eu fiquei um pouco em d√∫vida sobre como lidar com os logs e m√©tricas da aplica√ß√£o. Pensei em duas necessidades principais: 

1. Log de curto prazo (para debug e troubleshooting)

2. Armazenamento de logs a longo prazo (para auditoria ou an√°lise futura)

Para monitoramento e m√©tricas coloquei um EC2 rodando Seq, Prometheus e Grafana. Isso facilita a an√°lise da API em tempo real e permite visualizar os logs e m√©tricas sem precisar acessar diretamente os servidores.

Para armazenamento de logs a longo prazo inclu√≠ um Amazon S3 l√° posso arquivar logs antigos sem gastar muito.

Ainda n√£o sei se faz sentido salvar logs no DynamoDB para buscas r√°pidas. Vou avaliar se vale a pena ou se o pr√≥prio Seq j√° resolve essa necessidade.

Minha ideia foi manter tudo o mais simples e funcional poss√≠vel. Mas j√° pensei em algumas melhorias que poderiam ser feitas no futuro, sendo elas :

Usar servi√ßos gerenciados da AWS para observabilidade no lugar de rodar Prometheus e Grafana no EC2, poderia usar AWS Managed Grafana e Amazon CloudWatch.

üîπ O que foi feito? (**3h**)

- [x] Estudo dos servi√ßos AWS
- [x] Desenho da solu√ß√£o
- [x] Ajustes e melhorias no plano de arquitetura

üìå Dia 7 ‚Üí Documenta√ß√£o e revis√£o final (Tempo gasto: **3h**)

Hoje trabalhei a conclus√£o da documenta√ß√£o explicativas de como rodar a aplica√ß√£o em docker, fim uma revis√£o da api e vi oportunidades de melhoria.
Refatorei os metodos e separei do investimento os dados da conta, criando 2 tabelas, estrurei a api para comportar mudan√ßas e refiz a parte do EF para o migration,
Inclui tambem a autentica√ß√£o JWT de forma simples, incluindo uma nova controller para login e obter o token, e inclui nas controller a necessidade de autentica√ß√£o.
Configurei tambem o swagger para possibilitar a inclus√£o do token por ele para facilitar os teste.

üîπ O que foi feito? (**3h**)

- [x] Documenta√ß√£o final com passo a passo como rodar a aplica√ß√£o
- [x] Refatora√ß√£o da api
- [x] Incluso autentica√ß√£o JWT simples
- [x] Incluso autentica√ß√£o via Swagger

üìå Passo a passo para rodar a aplica√ß√£o no Docker

1. Instalar o Docker Desktop
- Baixar e instalar o Docker Desktop: (https://www.docker.com/products/docker-desktop/)
- Ap√≥s a instala√ß√£o, abrir o Docker Desktop e garantir que ele esteja rodando.

2. Baixar o c√≥digo-fonte
- Acessar o reposit√≥rio no GitHub: https://github.com/willianbraga/investimento-api/tree/feature/InvestimentoApi
- Clicar no bot√£o verde <> Code e selecionar a op√ß√£o Download ZIP.
- Ap√≥s o download, descompactar o arquivo em uma pasta de sua prefer√™ncia.

3. Acessar a pasta do projeto
- Navegar at√© a pasta descompactada e entrar no caminho: ...\investimento-api-feature-InvestimentoApi\investimento-api-feature-InvestimentoApi\Investimento\Docker
- Abrir um Prompt de Comando (CMD) nessa pasta.

4. Subir os containers no Docker
- No terminal (CMD), executar o seguinte comando: docker-compose up --build
- Aguardar a finaliza√ß√£o e verificar se os containers subiram corretamente com o comando: docker ps
- Se os containers n√£o estiverem rodando, revisar as mensagens de erro antes de continuar.

5. Configurar o banco de dados
- No terminal (CMD), executar o seguinte comando para acessar o container do SQL Server rodando no Docker: docker exec -it investimento-db /bin/bash
- Dentro do container, rodar o script de inicializa√ß√£o do banco: /docker-entrypoint-initdb.d/entrypoint.sh
- Ap√≥s a finaliza√ß√£o, sair do container: exit

6. Executar a migration para criar as tabelas
- No terminal (CMD), executar o seguinte comando para voltar um n√≠vel na estrutura do projeto: cd ..
- No terminal (CMD), executar o seguinte comando para acessar a pasta da API: cd Investimento.Api
- No terminal (CMD), executar o seguinte comando para rodar a migration para garantir que o banco esteja atualizado: dotnet ef database update --connection "Server=localhost,1433;Database=Investimento;User Id=user_api;Password=P4ssW0rd;TrustServerCertificate=True"

7. Acessar a API
- Abrir o navegador e acessar a URL: http://localhost:8080/swagger/index.html

- Se precisar resetar os containers
- Caso encontre problemas durante os testes, pode ser necess√°rio resetar os containers e reconstru√≠-los:
- docker-compose down -v --remove-orphans
- docker-compose up --build